{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77ffd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+-------------------+-------+-------+------+\n",
      "|EMPNO| ENAME|      JOB| MGR|           HIREDATE|    SAL|   COMM|DEPTNO|\n",
      "+-----+------+---------+----+-------------------+-------+-------+------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17 00:00:00|5000.00|   NULL|    10|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01 00:00:00|2850.00|   NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09 00:00:00|2450.00|   NULL|    10|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02 00:00:00|2975.00|   NULL|    20|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19 00:00:00|3000.00|   NULL|    20|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03 00:00:00|3000.00|   NULL|    20|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17 00:00:00| 800.00|   NULL|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20 00:00:00|1600.00| 300.00|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22 00:00:00|1250.00| 500.00|    30|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28 00:00:00|1250.00|1400.00|    30|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08 00:00:00|1500.00|   0.00|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23 00:00:00|1100.00|   NULL|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03 00:00:00| 950.00|   NULL|    30|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23 00:00:00|1300.00|   NULL|    10|\n",
      "+-----+------+---------+----+-------------------+-------+-------+------+\n",
      "\n",
      "+-----+-----+---+---+--------+---+----+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "|EMPNO|ENAME|JOB|MGR|HIREDATE|SAL|COMM|DEPTNO|EFF_STRT_DT|EFF_END_DT|MOST_RCNT_IN_CD|ETL_CHKSUM_NB|ETL_LOAD_TS|ETL_LST_UPDT_TS|\n",
      "+-----+-----+---+---+--------+---+----+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "+-----+-----+---+---+--------+---+----+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "\n",
      "JDBC connection test successful.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Replace with your Oracle connection details\n",
    "jdbc_url = \"jdbc:oracle:thin:@//localhost:1521/xe\"\n",
    "username = \"HR\"\n",
    "password = \"HR\"\n",
    "\n",
    "try:\n",
    "    # Create a Spark session with JDBC options\n",
    "    spark = SparkSession.builder.appName(\"JDBCConnectivityTest\").getOrCreate()\n",
    "    EMP_SRC_df = spark.read.jdbc(url=jdbc_url, table=\"EMP_SRC\",  properties={\"user\": username, \"password\": password})\n",
    "    EMP_PYSPARK_SCD2_df = spark.read.jdbc(url=jdbc_url, table=\"EMP_PYSPARK_SCD2\",  properties={\"user\": username, \"password\": password})\n",
    "    # If the connection was successful, you can print the result\n",
    "    EMP_SRC_df.show()\n",
    "    EMP_PYSPARK_SCD2_df.show()\n",
    "   # spark.stop()\n",
    "    print(\"JDBC connection test successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"JDBC connection test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cd3127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+----+---+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "|EMPNO|JOB|SAL|COMM|MGR|DEPTNO|EFF_STRT_DT|EFF_END_DT|MOST_RCNT_IN_CD|ETL_CHKSUM_NB|ETL_LOAD_TS|ETL_LST_UPDT_TS|\n",
      "+-----+---+---+----+---+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "+-----+---+---+----+---+------+-----------+----------+---------------+-------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1 : Identify the records to update\n",
    "from pyspark.sql.functions import col, lit, current_date\n",
    "# Assuming EMP_SRC_df and EMP_PYSPARK_SCD2_df are already defined\n",
    "# Step 1: Identify records to update\n",
    "updates_df = EMP_SRC_df.alias(\"src\") \\\n",
    "    .join(EMP_PYSPARK_SCD2_df.alias(\"tgt\"), on=\"EMPNO\",how=\"left_outer\") \\\n",
    "    .filter(\n",
    "        (col(\"src.JOB\") != col(\"tgt.JOB\")) |\n",
    "        (col(\"src.SAL\") != col(\"tgt.SAL\")) |\n",
    "        (col(\"src.COMM\") != col(\"tgt.COMM\")) |\n",
    "        (col(\"src.MGR\") != col(\"tgt.MGR\")) |\n",
    "        (col(\"src.DEPTNO\") != col(\"tgt.DEPTNO\"))\n",
    "    ) \\\n",
    "    .select(\"src.EMPNO\", \"src.JOB\", \"src.SAL\", \"src.COMM\", \"src.MGR\", \"src.DEPTNO\") \\\n",
    "    .withColumn(\"EFF_STRT_DT\", current_date()) \\\n",
    "    .withColumn(\"EFF_END_DT\", lit(None)) \\\n",
    "    .withColumn(\"MOST_RCNT_IN_CD\", lit(\"Y\")) \\\n",
    "    .withColumn(\"ETL_CHKSUM_NB\", lit(None)) \\\n",
    "    .withColumn(\"ETL_LOAD_TS\", current_date()) \\\n",
    "    .withColumn(\"ETL_LST_UPDT_TS\", current_date())\n",
    "    \n",
    "updates_df.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
